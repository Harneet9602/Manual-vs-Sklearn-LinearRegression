# Manual vs Sklearn Linear Regression

This repository contains a notebook that demonstrates the implementation of **Linear Regression** using:

- Manual Gradient Descent from scratch
- scikit-learnâ€™s `LinearRegression` model

The aim is to:
- Understand how Gradient Descent optimizes weights
- Compare manually obtained results with library-based implementations
- Visualize the regression line and evaluate model performance using Mean Squared Error (MSE)

---

## ğŸ“‚ Contents

- `DMML2.ipynb` â€“ The main Jupyter Notebook
- Uses `Training_set_heights200.csv` as the dataset

---

## ğŸ§  Concepts Covered

- Data preprocessing with Min-Max Scaling
- Manual implementation of Gradient Descent
- Train/Test Split
- Model fitting with `sklearn`
- Error computation (MSE)
- Visualization with Matplotlib

---

## ğŸ› ï¸ Libraries Used

- `pandas`
- `numpy`
- `matplotlib`
- `sklearn`

---

## ğŸ“Š Sample Output

- Scatter plot with predicted regression line
- Training vs Testing performance comparison
- Gradient Descent updates over epochs

---

## ğŸš€ How to Run

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/Manual-vs-Sklearn-LinearRegression.git
